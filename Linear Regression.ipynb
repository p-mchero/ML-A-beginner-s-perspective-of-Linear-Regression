{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "Written by: Paul Treve (Email: trevepaul2@gmail.com)\n",
    "\n",
    "Note: Based on the data provided, an accurate hypothesis should be $h_{\\theta}(x^{(i)})=X\\theta=1.5+2x_{1}^{(i)}+x_{2}^{(i)}$\n",
    "$$\\theta = \\left(\\begin{array}{cc} 1.5\\\\2\\\\1\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the parameters of hypothesis using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the data from the csv file into arrays I can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from the csv file\n",
    "raw_data = pd.read_csv('data.csv')\n",
    "\n",
    "m = len(raw_data) # number of training examples\n",
    "n = 2 # number of features\n",
    "\n",
    "# assuming the hypothesis is of the form X*theta where X is an m by n matrix and theta, an n by 1 matrix\n",
    "feature1 = np.array(raw_data['X']) #x1\n",
    "feature2 = np.array(raw_data['Y']) #x2\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(m),    # x0 is 1\n",
    "    feature1,\n",
    "    feature2\n",
    "]).transpose()\n",
    "\n",
    "Y = np.array([[z] for z in np.array(raw_data['Z'])]) # correct results\n",
    "\n",
    "# initializing theta as an n by 1 matrix made up of only ones\n",
    "theta = np.array([[1] for _ in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is X?\n",
    "X is the design matrix of $m$ rows and $(n+1)$ columns. An $m\\times(n+1)$ matrix with each row representing a training example of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 1., 2.],\n",
       "       [1., 4., 1.],\n",
       "       [1., 3., 2.],\n",
       "       [1., 2., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5] # first 5 rows of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Y?\n",
    "Y is an $m$ dimensional vector. An $m\\times1$ matrix with each element corresponding to the expected result of a specific training example of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.5],\n",
       "       [ 5.5],\n",
       "       [10.5],\n",
       "       [ 9.5],\n",
       "       [ 6.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5] # first 5 elements of Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hypothesis - $h_{\\theta}(x^{(i)})$\n",
    "Instead of taking each feature, $x_{n}^{(i)}$, one at a time in a training example to multiply with its corresponding $\\theta_{j}$, a more conservative way to do this is to vectorize the $\\theta$. Making $\\theta$ an $(n+1)$ dimensional vector, with the first element being the constant term in the expression $h_{\\theta}(x^{(i)}) = \\theta_{0} + \\theta_{1}x_{1}^{(i)} + \\theta_{2}x_{2}^{(i)} + ... + \\theta_{n}x_{n}^{(i)}$ and the rest of the elements being the coefficients of $x_{1}^{(i)}, x_{2}^{(i)}, ..., x_{n}^{(i)}$ where $n$ is the number of features of each training example. Multiplying the design matrix, X (an $m\\times(n+1)$ matrix), by $\\theta$ will produce an $m$ dimensional vector(an $m\\times1$ matrix). This vector contains the predictions of the hypothesis.\n",
    "$$h_{\\theta}(x^{(i)})=X\\theta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis():\n",
    "    return X @ theta # matrix product of X and theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some trials, a learning rate of $0.01$ is enough for the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the learning rate\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cost Function for Linear Regression\n",
    "$$J(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost():\n",
    "    return (1/(2*m))*(((hypothesis() - Y) ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gradient Descent\n",
    "$$\\theta_{j}:=\\theta_{j}-\\alpha\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta)$$\n",
    "But since I have decided to vectorize the $\\theta$, I can think of the gradient descent as:\n",
    "$$\\theta:=\\theta-\\alpha\\delta$$\n",
    "where $\\delta$ is representing the partial derivative of each of elements of $\\theta$. $\\delta$ will be an $(n+1)$ dimensional vector given by:\n",
    "$$\\delta=\\frac{1}{m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in the cell below does the update of the theta as it should be done - simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_theta():\n",
    "    x0 = np.array([[u] for u in X.transpose()[0]])\n",
    "    x1 = np.array([[u] for u in X.transpose()[1]])\n",
    "    x2 = np.array([[u] for u in X.transpose()[2]])\n",
    "    # computing the elements of the delta vector\n",
    "    delta0 = (1/m)*(((hypothesis() - Y)*x0).sum())\n",
    "    delta1 = (1/m)*(((hypothesis() - Y)*x1).sum())\n",
    "    delta2 = (1/m)*(((hypothesis() - Y)*x2).sum())\n",
    "    # computing the new values for the elements of theta\n",
    "    return np.array([\n",
    "        [theta[0, 0] - (alpha*delta0)],\n",
    "        [theta[1, 0] - (alpha*delta1)],\n",
    "        [theta[2, 0] - (alpha*delta2)]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A while loop to update the theta and keep the gradient descent going until the cost is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "costs = np.array([])\n",
    "number_of_steps = 0\n",
    "while True:\n",
    "    # keeping track of the number of steps and the gradient descent at each step\n",
    "    # this is to help plot a graph of cost against number of steps\n",
    "    # to show that the gradient descent actually worked\n",
    "    number_of_steps += 1\n",
    "    costs = np.append(costs, cost())\n",
    "    # calculation of accuracy of model in terms of MSE\n",
    "    mean_sq_error = 2*cost()\n",
    "    # making sure the cost is minimun\n",
    "    if cost() < 10**(-20):\n",
    "        print(\"Success.\")\n",
    "        break\n",
    "    # updating the theta simultaneously\n",
    "    theta = new_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "----------------\n",
      "Theta:\n",
      " [[1.5]\n",
      " [2. ]\n",
      " [1. ]]\n",
      "Mean Squared Error(MSE):  0.000000000000000\n"
     ]
    }
   ],
   "source": [
    "# printing out results on the screen\n",
    "print(\"Results\\n----------------\")\n",
    "print(f\"Theta:\\n {theta}\\nMean Squared Error(MSE): {mean_sq_error: .15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Costs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAACgCAYAAAArWZqvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg2UlEQVR4nO2deXxdVbn3v78kTcvQFmgLQps2oIKUSaEMB1QCRUFmEVCGW3jFy6vAxepVEPBqeb3XqoiW+3pBCvqWSREUqIIXuBbiRCi0UJBRQDpCaQstLaXN+Lx/rHXSncNJcpLs5JycPN989idrD2utZ+3z7P1bw95ry8xwHMdxnL5SUWwDHMdxnPLABcVxHMdJBRcUx3EcJxVcUBzHcZxUcEFxHMdxUsEFxXEcx0mFARUUSbWSTFLVAOS1laTfSXpb0p39nV+pI+lZSXVFyHfAfvM0kVQnaXkR8/+0pGWS3pH0kWLZ4Tg9oWBBkVQvaa2k4f1pUCK/GZJu7UMSpwI7AWPM7LRO8thd0p2S1kTheVrSVyVV9jbTFOzuF8xsLzOr70sahZRN0mJJR/UlHweAHwIXmdm2ZvZkoZEkzZH07/1ol+N0SkGCIqkW+BhgwIn9aVCKTAL+bmYt+XZKej8wH1gG7GNmo4HTgCnAyAGz0il7etk6mwQ8m7YtjtOvmFm3C/At4K/Aj4B7uzm2HpgJPAa8DcwFdoj7agmiVBXXdwF+C7wFvAz8c9x+DNAENAPvAE91kteeMb91hIvvxLj9ypz45+WJeytwXzdlOTGmuy7ms2di36XACmAD8CIwtTO7gXOBf8RjXwXO6iS/g4CGmN/rwE+A6sT+T8a83gauBf4IfCHuez/wEPAmsAa4DdguEXcxcFQMzwDuAG6ONj0LTOlN2XLsvwVoAzbFYy5J/ObnAEujbVck4lQA3wBeibbfkfWXPOnXAcuBfwVWxXP0v3J87wuJ9XOBvyTWDbgAeCmW7TvxvDUA62Pe1Tl5XR5tXpz83YDhhFbEUuAN4KfAVjlxLwVWArfkKUsF8E1gSSzLzcDomO470daNwCt54gr4cYz3NvA0sDdwfvx9mmIav0tcZ78BVhP87+JEWjOAXwO/iufkCWC/rnyhkHuGL0NzKeygcLO/ADggOuxOXRxbHx1wb2Cb6Mi3xn3Zm0tWUP5IuDGOAD4cHX5q3DcjG6+TfIZFuy4HqoEjo9PvUWD8lSRuRnn27x4v6E/EvC6J+VUDexBaNrskyvX+fPnGc7A+YdfOwF6d5HkAcAhQFdN8Hpge942N6ZwS9385/hZZQflAtHU4MA74EzArkfZiOgrKZuBYoJJQAXg07iu4bJ2UoT2fnN/8BmArYD+gkSjOwHTgUWBCtP164JedpF0HtAD/J/4mxwLvAtsnfK87QfktMArYK9oxD9iNcDN/DjgnJ68fRbsOj/6Q/R1nxbR2ILRofwfMzIn7/Rh3qzxl+TzBn3YDtgXuIiE80dYPdHIejgYWAtsRxGVPYOe4bw7w74ljK+Kx3yL47m6Eys3Rid+0mdBFPAz4GkF0hnXlC774km/p/gD4aHS4sXH9BeArXRxfD3wvsT6ZUGOqJCEoQA3QCoxMHDsTmBPDM+haED5GEIWKxLZfAjMKjN8MHNPF/n8D7kisVxCEso5w814FHAUMy4nXIV+CoKwDPpPvxtLNuZ8O3B3D04CGxD7Fi/0LncQ9GXgysb6YjoLyh5zfaFMMF1y2TvJtzyeuZ3/zCYltjwGfi+HnSdR6CYLbTKx05KRdR2j9VCW2rQIOSfhed4JyWGJ9IXBpYv1qogizRRS2Sey/I/qFCOLy/sS+DPBqIm4TMKKL8zQPuCCxvkey3HQtKEcCfydUPipy9s2ho6AcDCzNOeYy4P8lftNHc/z8dcL11akv+OJLvqWQMZRzgAfNbE1c/0Xc1hXLEuElhNrO2JxjdgHeMrMNOceOL8CmbPxlZtbWy/hvEm5eXaW/JLsS81kGjDezlwk3+xnAKkm3S9olXyJmthH4LPBF4HVJ90n6UL5j40MC90paKWk98F22nLddSJxXMzNCt0o27o7RjhUx7q2895wnWZkIvwuMkFTVk7L1kNz8to3hScDdktZJWkcQmFbCAxX5eNM6josl0yqENxLhTXnWk2mtjb9fliWE32EcsDWwMGH3/XF7ltVmtrkLOzr4VwxX0Xm52zGzhwjdof8FvCFptqRRnRw+Cdgla2e09fKcfJJ+1Ubwq1360RecMqVLQZG0FXA6cHi8ya0EvgLsJ2m/LqLWJMITCTWvNTnHvAbsIGlkzrErYti6sf01oEZSsgzJ+N3xB0Kroav0J2VXJIlQrhUAZvYLM/toPMYI3Rt57TazB8zsEwQBe4HQ/ZOP6+L+D5rZKMKFr7jvdUK3UNKeCYm4M2Pe+8a4Zyfi9oielC1f9B5mtwz4lJltl1hGmFmhv2OSjYQbfZb39SKNJNtL2iaxPpHgF2sI4rNXwubRZpYUo0L8d1JifSKhRfRG/sM7Ymb/aWYHELrudge+3km+ywgtp+T5HWlmxyaOab9e4/U0IdrXlS84znvoroVyMqG2OJkwxvFhQn/tnwldMJ1xtqTJkrYm9Hf/2sxakweY2TLgEWCmpBGS9gXOIwwmQ7iwanMEI8l8wg3kEknD4jsWJwC3d1OmLN8GDpV0laT3AUj6gKRbJW1H6N44TtJUScMIA8GNwCOS9pB0ZHyEejPh5pItXwe7Je0k6cR4Y2okDJZ2OBcJRhLGSd6JrZgvJfbdB+wj6eT41NCFdLxhjoxpr5M0ni03mB7Rk7J1whuEfvpC+SnwH5ImxfzHSTqpF6YDLAJOkbS1pA8Q/KmvXCmpWtLHgOOBO2Mt/gbgx5J2jHaPl3R0D9L9JfAVSbtK2pbQGv2VdfJUYhJJB0o6OPrlRsLvlPyNkuf/MWC9pEvju1mVkvaWdGDimAMknRL9ajrBTx/txhcc5z10JyjnEPpal5rZyuxCaG6f1cXjkLcQ+nJXEgbcL+7kuDMIfeyvAXcD3zaz/4n7si8jvinpidyIZtZEeArrU4Qa47XANDN7oZsyZeO/Quj3rgWelfQ24QGCBcAGM3uRUMv/vzH9E4ATYr7Dge/F7SuBHQmtiXx2VxDE6DXC02yHEx5wyMfXgDMJDxfcQHjyJmvvGsJjzT8gdNdNjrY2xkOuBPYnPPVzH2GQtzf0pGz5mAl8M3avfK2A/K4hDG4/KGkDYYD+4F7a/mPC2MUbwE1sqZz0lpXAWsJvdxvwxYR/XUoYVH80djH+gTAOUig/J1wnfyIMgm8G/qXAuKMI/rGW0FX2JuGJM4CfAZPj+b8nVuROIFQGXyX8rjcSHkLIMpfQLbsW+CfgFDNrpmtfcJz3oNAVn2KCUj1h4PbGVBN2OhBbCcsJj7I+XGx7nMGJpBmEwf+zi22LM/jxubwGEZKOlrRd7ILIjq88WmSzHMdxABeUwUaG8AJgtgvuZDPbVFyTHMdxAql3eTmO4zhDE2+hOI7jOKngguI4juOkwqD6RkWajB071mpra4tthlOmLFy4cI2Zjev+yPRx33b6k658e8gKSm1tLQsWLCi2GU6ZImlJ90f1D+7bTn/SlW97l1cuDQ0wc2b47zhlRMOyBmb+eSYNy9y3nf5hyLZQ8tLQAEceCU1NMHw4zJsHmUyxrXKcPtOwrIEjbjqC5rZmhlcOZ960eWRq3LeddPEWSpL6emhshLa2ICr19cW2yHFSoX5xPY2tjbRZG02tTdQvri+2SU4Z4oKSpK4OKuPn5Kurw7rjlAF1tXUoTj5dXVlNXW1dcQ1yyhIXlCSZDJx+OlRVeXeXU1ZkajJ8bNLH2HGbHb27y+k3XFBymTAhCIqLiVNm7P++/dnYtJFDJhxSbFOcMsUFJR8+HY1ThkwcPZGNzRtZu3ltsU1xyhQXlFzUq48cOk7JM2m78IHIJeuK9oqMU+a4oDjOEGHi6IkALHnbBcXpH1xQ8uFdXk4ZMml0aKEsfXtpkS1xyhUXlFy8y8spU8ZuPZatqrbyLi+n33BByYe3UJwyRBITR09k6XpvoTj9gwtKLt5CccqYSdtN8haK02+4oDjOEGLS6Ek+KO/0Gy4o+fAuL6dMmTh6Iqs2rmJT86Zim+KUIS4ouXiXl1PGZJ/0WrZ+WZEtccqRshIUSZWSnpR0b7FtcZw0Scu3/eVGpz8pK0EBvgw83+dUvMvLKT1S8e3sy43+LorTH5SNoEiaABwH3NjHhFKxx3HSIjXfBsaPHE+FKnxg3ukXykZQgFnAJUBbZwdIOl/SAkkLVq9e3XlK3kJxSotZdOPbhTKschi7jNzFBcXpF8pCUCQdD6wys4VdHWdms81siplNGTduXGeJ9YOFjtM7CvXtgitLhIF57/Jy+oOyEBTgMOBESYuB24EjJd1aXJMcJxUK8u2CKksRf7nR6S/KQlDM7DIzm2BmtcDngIfM7Ow+JJiWaY7TJ1L3bWDiqIksW7+M1rbWVGx0nCxlISip4l1eTpkzabtJtLS1sPKdlcU2xSkzyk5QzKzezI7vdQLLl4cWSkNDilY5Tt/ps29Hsi83fudP36Fhmfu5kx5lJyh9oqEBbrklhKdOdVFxypK3Nr0FwA0Lb2DqzVNdVJzUcEFJUl8PrbFfuakprDtOmfHy2pcBaKONptYm6hfXF9cgp2xwQUlSVweVlSFcXR3WHafM+ORun0Txr7qymrraumKb5JQJLihJMhmYNi2E580L645TZmRqMmQmZNhp252YN20emRr3cycdXFByqakJ/w85pLh2OE4/ctjEw1i7aS0Hjj+w2KY4ZYQLSi7+2LAzBJg8bjKNrY28uvbVYpvilBEuKI4zBJk8bjIAz61+rsiWOOWEC0pn+NvyThmz59g9ARcUJ11cUHLxLi9nCDBy+EhqRtXw3BoXFCc9XFAcZ4gyedxkb6E4qeKC0hne5eWUOZPHTeb51c/TZn3+zIrjACUoKJJOkzQyhr8p6S5J+w+gAQOWlTO0KLpv5zB53GQ2tWzyqeyd1Cg5QQH+zcw2SPoocDRwE3DdgFvhLRQnfUrDtyP+pJeTNqUoKNmPNBwHXGdmc4HqAcvdWyhO/1Fc387Bn/Ry0qYUBWWFpOuB04HfSxpOadrpOD2lpHx7+622Z+dtd/YnvZzUKMUb9enAA8AxZrYO2AH4+oDlvjR+a9unrnfSp7i+nQd/0stJk1IUlOvN7C4zewnAzF4H/mlAcm5ogDlzQvjoo11UnLQpnm93wvYjtmfRykU8svSRYprhlAmlKCh7JVckVQIHDEjO9fXQ0hLC/j0UJ32K59t5aFjWwNwX59LU2sTUW/xDW07fKRlBkXSZpA3AvpLWx2UDsAqYOyBG1NVBVVUI+/dQnJQoCd/OQ/3ielotPCfgH9py0qBkBMXMZprZSOAqMxsVl5FmNsbMLhsQIzIZ+PznQ/j++/17KE4qlIRv56Guto7hlcMBqFCFf2jL6TMlIygJ7pW0DYCksyX9SNKkAct94sTw/+CDByxLZ8hQXN/OIVOTYd60eUwYNYG9d9zbP7Tl9JlSFJTrgHcl7QdcAiwBbh6w3P09FKf/KK5v5yFTk+HUPU/lxTUv0tzaXExTnDKgFAWlxcwMOAm4xsyuAUYOuBX+pryTPqXh2zlkajJsatnEU288VWxTnEFOKQrKBkmXER6nvC8+CTNswHL3ForTfxTXtzvh0JpDAXhkmT867PSNUhSUzwKNwOfNbCUwHriquCY5TiqUpG9PGDWBmlE1LihOnyk5QYkX2m3AaEnHA5vNbOD7mb3Ly0mZkvHtPGRqMjQs9/dQnL5RcoIi6XTgMeA0wlQV8yWdOoAGDFhWztCi6L7dBYdOOJSlby9lxfoVxTbFGcRUFduAPFwBHGhmqwAkjQP+APy6q0iSaghPzLwPaANmx0HP3uEtFCd9euXbA0F2HKVheQOnTi4JjXMGISXXQgEqshdc5E0Ks7MF+Fcz2xM4BLhQ0uQe556dHHL+/B5HdZxu6LFvS6qR9LCk5yU9K+nL/WHYfu/bjxFVI3wcxekTpSgo90t6QNK5ks4F7gN+310kM3vdzJ6I4Q3A84RBz8JpaIAbbgjh447zySGdtOmNb6dTUeqG6spq9hizB3c+d6fP6eX0mpIRFEkfkHSYmX0duB7YF9gPaABm9zCtWuAjQM+aGT45pNMP9MW3U6koFUDDsgaeXf0sy9cvZ+rNPlGk0ztKRlCAWcAGgDjF91fN7CuEGtysQhORtC3wG2C6ma3P2Xe+pAWSFqxevfq9kX1ySKd/mEU6vl1LbypKBVC/uJ62tjYAGlsbfaJIp1eUkqDUmtnTuRvNbAFQW0gCkoYRxOQ2M7srT1qzzWyKmU0ZN27cexPIZOD880P43nt9ckgnLdLw7U4rSnF/15WlbqirrWN4VZgoUsgninR6RSkJyogu9m3VXWRJAn4GPG9mP+q1FZPiXH0HHdTrJBwnh776dpcVJSigstQN2Yki991pX0ZWj+Sg8e7/Ts8pJUF5XNI/526UdB6wsID4hxGmtDhS0qK4HNtjK/w9FCd9eu3bqVWUCiBTk+Hyj17OusZ1PLr80f7MyilTSuk9lOnA3ZLOYstFNgWoBj7dXWQz+wuQnhr4eyhOekyn976drSj9TdKiuO1yM+v2ycfe8KkPfophFcOY++JcDpt4WH9k4ZQxJSMoZvYGcKikI4C94+b7zOyhATXEWyhOyvTFt1OvKHXDqOGjOGLXI5j74lx+8IkfDFS2TplQMoKSxcweBh4umgGLF4f/8+fDUUcVzQyn/Ci6bxfISXucxIW/v5AX1rzAh8Z+qNjmOIOIUhpDKT4NDXD99SF84on+YqMzJDlh9xMAmH7/dH8fxekRLihJ/MVGx2H5+uUI8cArD/hLjk6PcEFJ4i82Ok6HlxqbWpv8JUenYFxQkmQy8KUvhfDcuf5iozMkSb7kmF13nEJwQcmltjb89xcbnSFKpibDQ9Me4oCdD6Cqooo9x+1ZbJOcQYILSi7Jp7wcZ4iSqckw+4TZNLY2MmfRnGKb4wwSXFCSNDTAddeF8Mkn+1NezpBm/53359CaQ7n28Wtps7Zim+MMAlxQkvhTXo7TgYsOvIiX3nqJ8+ae5097Od3igpLEn/JynA6MHxU+vTLnqTn+CLHTLS4oSTIZuOCCEL77bn/Kyxny/HXpX1Gc+cW/k+J0hwuK4zidUldbx4iqMPu+mXFozaFFtsgpZVxQkjQ0wLXXhvCnP+2D8s6QJ/udlHP3OxfDmL/Cn350OqfkJocsKvkG5b3byxniZGoyZGoyrNm0hivrr2Td5nWcsPsJZGr82nA64i2UJMlB+WHDfFDecRKcvc/ZvNvyLjP/MtMH6J28uKAkyWTglFNC+Lvf9daJ4yT4x9p/tA/Qb27Z7AP0zntwQUnS0AB3xU92X365j6E4ToLsAL0QhvHGxjeY+eeZ3lJx2vExlCT19dDcHMI+huI4HcgO0D/4yoPMfmI218y/hgpVMLxyOPOmzfMxFcdbKB0YM2ZLuK2t47rjOGRqMny77tucsfcZALRZm09x77TjgpLkzTe3hKWO647jtPOZPT/T/n5Kq7Xy2GuPedeX44LSgWSLxMxbKI7TCdkp7s/c50yEuOeFezh8zuE8svSRYpvmFBEXlCRPPtn1uuM47WRqMuw9bm8qFG4jzW3NnHnXmVwx7wpvrQxRfFA+ycqVXa87jtOButo6qiuraWptAmDJ20v47l++y1WPXMXVn7yad5reoa62zgfshwguKI7j9Jrsk1/1i+tZ+vZSZj8xmzZro7mtmYvvvxghhlcN55pjruHNd990cSlzXFCSvPVW1+uO47yH7NQsDcsauOmpm9pbK63WimFsbtnMF+/9IkJUV1W7uJQxLihJnnmm63XHcTol2VoZs/UYpt8/nabWJgyjzdo6iAvAsMphXHn4lbTRxtitx7aLDED94noXnEGIC0oSb6E4Tp/ItlYA9tlxn07FBaCptYnLHrqsQ/xKVSKJNmujurKaH37ih6xvXP8eocmGx2w9xoWohCgrQZF0DHANUAncaGbf63Ois2fD+ef3ORnHGWp0Jy5Ae8slS6u1kl3d3LKZi/77ovZ92SlfKqhAUjg2bq+sqESI1rZWhlUO49LDLuXd5nf5+KSPM6JqBPNXzOfI2iORVLAo9STswhaQmXV/1CBAUiXwd+ATwHLgceAMM3su3/FTpkyxBQsW5CbSz1Y6ZcnIkbB+fYdNkhaa2ZQ0ku9pRSmvb5cQDcsaOohLY0sjbbRRoQqqKkIdt6UtfEbCzDoITn8i1N46qqACFPLvsD0+Ip0NS2q3NZ+wXXjghWxs3siBuxxIVUUVi1YuIjMhQ1VlFY+veJwxW49hfeN6Dp90OFUVVfx12V85ovYIoO9ilkYa+QSxK98uJ0HJADPM7Oi4fhmAmc3Md7wLipMqOaKSlqD0tKIEpS8oSZLikntDS7ZmsjfqlraW9nBza3MHITIzWq0VofaWT7ZVUy4ky5NbtqTw9UQcky29ClUEQbRWRlSNyDtHW1e+XU5dXuOBZYn15cDByQMknQ+cDzBx4sT3pmDmouL0jg0b+ivlg4CXzewfAJJuB04COhWUwUSyWyx3O2zpKutJzbo7IepKlLo6Nl8YoKW1JaRBBVWVVWBbbtL5hK0vIpeMl5uGYWQbCMlwG23t3YiGtYezNibjJ7dl52jrSbddOQlKPiXocMbNbDYwG0ItbiCMcoYII0f2V8rdVpTKmVzB6Sycu607IRqILqOetrB6Kmb9nUZ1ZXV7eQqlnARlOVCTWJ8AvNbjVLyV4vSUPGMoKdJtRQkKaH0PMQoVoq5EqTfh3G29aWGlNf6RRho9faignMZQqgh9zVOBFYS+5jPN7Nl8xw+mfmZn8JHiGEqPxgbBfdvpX7ry7bKZHNLMWoCLgAeA54E7OhMTxxlEPA58UNKukqqBzwG/LbJNjpOXsmmh9BRJq4ElneweC6wZQHOKyVAp60CXc5KZjUsjIUnHArMIjw3/3Mz+o5vjh7Jvl3v5oPhl7NS3h6ygdIWkBWm9Q1DqDJWyDpVydke5n4dyLx+UdhnLpsvLcRzHKS4uKI7jOE4quKDkZ3axDRhAhkpZh0o5u6Pcz0O5lw9KuIw+huI4juOkgrdQHMdxnFRwQclB0jGSXpT0sqRvFNueQpD0c0mrJD2T2LaDpP+R9FL8v31i32WxfC9KOjqx/QBJf4v7/lMKUwZIGi7pV3H7fEm1A1rALfbVSHpY0vOSnpX05bi97MqaNoPRr7ujN/4wGJFUKelJSffG9dItn5n5Yu0TqVUCrwC7AdXAU8DkYttVgN0fB/YHnkls+wHwjRj+BvD9GJ4cyzUc2DWWtzLuewzIEKb7+G/gU3H7BcBPY/hzwK+KVM6dgf1jeCRhZoTJ5VjWlM/boPTrtP1hsC7AV4FfAPfG9ZItn7dQOtI+s6uZNQHZmV1LGjP7E5D7ecmTgJti+Cbg5MT2282s0cxeBV4GDpK0MzDKzBoseOrNOXGyaf0amJqt0Q8kZva6mT0RwxsIMyKMpwzLmjKD0q+7oxf+MOiQNAE4Drgxsblky+eC0pF8M7uOL5ItfWUnM3sdwoUH7Bi3d1bG8TGcu71DHAtT3LwNjOk3ywsgdkV9BJhPmZc1BcrJr/NSoD8MRmYBlwBtiW0lWz4XlI4UNLPrIKezMnZV9pI6L5K2BX4DTDezrqb5HfRlTYlyLFM7PfCHQYWk44FVZraw2LYUigtKR9KZAr80eCN27RD/r4rbOyvj8hjO3d4hTpzVeTTv7WIbECQNI9w8bjOzu+LmsixripSTX3egh/4w2DgMOFHSYkI35ZGSbqWEy+eC0pFymtn1t8A5MXwOMDex/XPxaaZdgQ8Cj8Wm8wZJh8Qxg2k5cbJpnQo8FMceBpRo18+A583sR4ldZVfWlCknv26nF/4wqDCzy8xsgpnVEn6zh8zsbEq5fMV+KqDUFuBYwtMirwBXFNueAm3+JfA60EyojZ5H6PefB7wU/++QOP6KWL4XiU83xe1TgGfivp+w5cXXEcCdhEHtx4DdilTOjxK6ap4GFsXl2HIsaz+cu0Hn1/3hD4N1AerY8pRXyZbP35R3HMdxUsG7vBzHcZxUcEFxHMdxUsEFxXEcx0kFFxTHcRwnFVxQHMdxnFRwQSkRJJmkqxPrX5M0I6W050g6NY20usnntDjz68MFHn95f9vkFB/37aGDC0rp0AicImlssQ1JIqmyB4efB1xgZkcUePyQvOiGIO7bQwQXlNKhhfBpz6/k7sithUl6J/6vk/RHSXdI+ruk70k6S9Jj8Vsf708kc5SkP8fjjo/xKyVdJelxSU9L+t+JdB+W9Avgb3nsOSOm/4yk78dt3yK8aPZTSVflHL+zpD9JWhTjfEzS94Ct4rbb4nFnR9sXSbo+e8FLekfS1ZKekDRP0ri4/WJJz0Xbb+/1mXf6G/ftoeLbxX6z0pewAO8Ao4DFhPmjvgbMiPvmAKcmj43/64B1hO9CDAdWAFfGfV8GZiXi30+oQHyQ8Db9COB84JvxmOHAAsJ3Q+qAjcCueezcBVgKjAOqgIeAk+O+emBKnjj/Snw7m/BtjpHJcsTwnsDvgGFx/VpgWgwbcFYMfwv4SQy/BgyP4e2K/Rv64r491H27CqdkMLP1km4GLgY2FRjtcYtTWUt6BXgwbv8bkGye32FmbcBLkv4BfAj4JLBvooY4mnBRNhHmvHo1T34HAvVmtjrmeRvhA1/3dGUj8HOFifzuMbNFeY6ZChwAPK7w+ZGt2DLpXRvwqxi+FchOAvg0cJuke7rJ3yky7ttDw7e9y6v0mEXor90msa2F+FspeGR1Yl9jItyWWG+DDhWG3Dl2stO4/4uZfTguu5pZ9qLd2Il9Pf7YlIUPgH2cUMu8RdK0TtK9KWHLHmY2o7Mk4//jgP8iXKwLFWYHdkqXWbhvl7Vvu6CUGGb2FnAH4cLLspjgWBC+1jasF0mfJqki9j3vRpgs8QHgS7F2haTdJW3TVSKEDxgdLmls7Ac+A/hjVxEkTSJ81+EGwuyw+8ddzdm8CZPcnSppxxhnhxgPgp9ma5pnAn+RVAHUmNnDhA8QbQds2+1ZcIqG+3b5+/agUL0hyNXARYn1G4C5kh4jOGdnNayueJFwcewEfNHMNku6EagFnoi1w9V08zlRM3td0mXAw4Sa1+/NrLvps+uAr0tqJvSnZ2txs4GnJT1hZmdJ+ibwYLygmoELgSWE8u4laSHhC4qfJfRX3yppdLTjx2a2rtCT4RQN9+0y9m2fbdgpeSS9Y2aDoobmOD2h3Hzbu7wcx3GcVPAWiuM4jpMK3kJxHMdxUsEFxXEcx0kFFxTHcRwnFVxQHMdxnFRwQXEcx3FSwQXFcRzHSYX/D3cOCNJQXrazAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a plot of costs against number of steps taken in gradient descent.\n",
    "# The nature of the graph determines the success of the gradient descent.\n",
    "plt.subplot(221)\n",
    "plt.plot(range(number_of_steps), costs, '.-r')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Costs')\n",
    "plt.title('A plot of Costs against the number of steps')\n",
    "plt.subplot(222)\n",
    "plt.plot(range(50), costs[:50], '.-g')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Costs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the parameters of hypothesis using the Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the data from the csv file into arrays I can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "x_feature = np.array(data['X'])\n",
    "y_feature = np.array(data['Y'])\n",
    "\n",
    "Y = np.array([[z] for z in data['Z']])\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(len(x_feature)),\n",
    "    x_feature,\n",
    "    y_feature\n",
    "]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is X?\n",
    "X is the design matrix of $m$ rows and $(n+1)$ columns. An $m\\times(n+1)$ matrix with each row representing a training example of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 1., 2.],\n",
       "       [1., 4., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3] # first 3 rows of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Y?\n",
    "Y is an $m$ dimensional vector. An $m\\times1$ matrix with each element corresponding to the expected result of a specific training example of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.5],\n",
       "       [ 5.5],\n",
       "       [10.5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:3] # first 3 elements of Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normal equation\n",
    "The normal equation is given by:\n",
    "$$\\theta = (X^{T}X)^{-1}X^{T}Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linalg.inv(X.transpose() @ X) @ X.transpose() @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "----------------\n",
      "Theta:\n",
      " [[1.5]\n",
      " [2. ]\n",
      " [1. ]]\n"
     ]
    }
   ],
   "source": [
    "# printing out results on the screen\n",
    "print(\"Results\\n----------------\")\n",
    "print(f\"Theta:\\n {theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data used for the aboves codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X       15 non-null     int64  \n",
      " 1   Y       15 non-null     int64  \n",
      " 2   Z       15 non-null     float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 488.0 bytes\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>8.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.060099</td>\n",
       "      <td>1.187234</td>\n",
       "      <td>2.503331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X          Y          Z\n",
       "count  15.000000  15.000000  15.000000\n",
       "mean    2.466667   2.533333   8.966667\n",
       "std     1.060099   1.187234   2.503331\n",
       "min     1.000000   1.000000   4.500000\n",
       "25%     2.000000   1.500000   7.500000\n",
       "50%     2.000000   3.000000   8.500000\n",
       "75%     3.000000   3.500000  10.500000\n",
       "max     4.000000   4.000000  13.500000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X  Y     Z\n",
       "0   2  3   8.5\n",
       "1   1  2   5.5\n",
       "2   4  1  10.5\n",
       "3   3  2   9.5\n",
       "4   2  1   6.5\n",
       "5   2  2   7.5\n",
       "6   1  4   7.5\n",
       "7   3  3  10.5\n",
       "8   1  1   4.5\n",
       "9   3  4  11.5\n",
       "10  4  4  13.5\n",
       "11  3  1   8.5\n",
       "12  2  3   8.5\n",
       "13  2  4   9.5\n",
       "14  4  3  12.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
